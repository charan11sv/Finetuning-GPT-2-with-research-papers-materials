# Finetuning-GPT-2-with-research-papers-materials
Finetuned GPT-2 with a largedataset of 2.68 GB of text data from a research publications website which comprised of papers,articles,books etc from various topics of my interest(i.e in Data science and ML and all the subjects and applications revolving around them). Everything was done within my pc.
